{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b583a02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "13bbd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6b9bf232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['group1', 'group 2', 'group_3', 'group 4', 'group_5']\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "excel_file = pd.ExcelFile(\"/Users/megankelly/ASDA/Lego_Database1-11-2025.xlsx\")\n",
    "\n",
    "# See what sheets it contains\n",
    "print(excel_file.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a4ac4750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id      color is duplo? size type base shape base dimensions  \\\n",
      "0 NaN  Dark Blue      True     Brick  Rectangle           2 x 4   \n",
      "1 NaN      Green      True     Brick  Rectangle           2 x 4   \n",
      "2 NaN      Coral      True     Brick     Square           2 x 2   \n",
      "3 NaN        Red      True     Brick     Square           2 x 2   \n",
      "4 NaN      White      True     Brick     Square           2 x 2   \n",
      "\n",
      "   number of studs has slope?  slope degree in stock  transparent  \n",
      "0                8      False           NaN        1          NaN  \n",
      "1                8      False           NaN        1          NaN  \n",
      "2                4      False           NaN        1          NaN  \n",
      "3                4      False           NaN        1          NaN  \n",
      "4                4      False           NaN        1          NaN  \n",
      "Total rows: 204\n"
     ]
    }
   ],
   "source": [
    "# Read all sheets into a dictionary of DataFrames\n",
    "all_sheets = pd.read_excel(\"Lego_Database1-11-2025.xlsx\", sheet_name=None)\n",
    "\n",
    "# Combine them all\n",
    "df_combined = pd.concat(all_sheets.values(), ignore_index=True)\n",
    "\n",
    "print(df_combined.head())\n",
    "print(f\"Total rows: {len(df_combined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0090ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the id column with index\n",
    "df_cleaned = df_combined\n",
    "df_cleaned['id'] = range(1, len(df_cleaned) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be3131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dark Blue', 'Green', 'Coral', 'Red', 'White', 'Light Green',\n",
       "       'Orange', 'Yellow', 'Brown', 'Purple', 'Lilac', 'Orchid',\n",
       "       'Dark Grey', 'Light Grey', 'Pink', 'Dark Green', 'Cream', 'Black',\n",
       "       'Red Brown', 'Neon Yellow', 'Cyan', 'Denim Blue', 'Ice Blue',\n",
       "       'Capri', 'Shiny Green', 'Olive Green', 'Beige', 'Bright Pink',\n",
       "       'Transparent', 'lightgreen', 'lightbrown', 'lightpink', 'red',\n",
       "       'yellow', 'darkblue', 'darkgreen', 'darkpink', 'orange',\n",
       "       'darkpurple', 'lightpurple', 'white', 'grey', 'mudbrown', 'black',\n",
       "       'turquoise', 'lightblue', 'neon orange', 'neon dark yellow',\n",
       "       'neon light yellow', 'darkbrown', 'bright green', 'pink', 'peach',\n",
       "       'blue', 'pear', 'dark green ', 'dark green', 'sky blue',\n",
       "       'bright yellow', 'navy blue', 'purple', 'maroon', 'cream', 'khaki',\n",
       "       'neon green', 'neon yellow', 'neon blue', 'coral', 'lime green',\n",
       "       'green', 'brick red', 'cyan', 'baby blue', 'cafe', 'hot magent',\n",
       "       'Green ', 'Blue', 'Grey', 'Sky Blue', 'Deep Blue', 'Sky blue',\n",
       "       'Transparent yellow', 'Transparent orange', 'Blck',\n",
       "       'Transparent sky blue'], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Color column cleaning\n",
    "#df_cleaned[\"color\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065d36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['darkblue', 'green', 'coral', 'red', 'white', 'lightgreen',\n",
       "       'orange', 'yellow', 'brown', 'purple', 'lilac', 'orchid',\n",
       "       'darkgrey', 'lightgrey', 'pink', 'darkgreen', 'cream', 'black',\n",
       "       'redbrown', 'neonyellow', 'cyan', 'denimblue', 'iceblue', 'capri',\n",
       "       'shinygreen', 'olivegreen', 'beige', 'brightpink', 'transparent',\n",
       "       'lightbrown', 'lightpink', 'darkpink', 'darkpurple', 'lightpurple',\n",
       "       'grey', 'mudbrown', 'turquoise', 'lightblue', 'neonorange',\n",
       "       'neondarkyellow', 'neonlightyellow', 'darkbrown', 'brightgreen',\n",
       "       'peach', 'blue', 'pear', 'skyblue', 'brightyellow', 'navyblue',\n",
       "       'maroon', 'khaki', 'neongreen', 'neonblue', 'limegreen',\n",
       "       'brickred', 'babyblue', 'cafe', 'hotmagent', 'deepblue',\n",
       "       'transparentyellow', 'transparentorange', 'blck',\n",
       "       'transparentskyblue'], dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_cleaned[\"color\"] = df_cleaned[\"color\"].str.lower().str.replace(\" \", \"\")\n",
    "#df_cleaned[\"color\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1c110d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([True, False, 'yes', 'no'], dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is Duplo? column cleaning\n",
    "# Print unique values\n",
    "df_cleaned[\"is duplo?\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2fa655d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "# Standardize strings\n",
    "df_cleaned[\"is duplo?\"] = df_cleaned[\"is duplo?\"].astype(str).str.lower()\n",
    "\n",
    "# Standardize values\n",
    "df_cleaned[\"is duplo?\"] = df_cleaned[\"is duplo?\"].map({\n",
    "    \"yes\": 1,\n",
    "    \"true\": 1,\n",
    "    \"1\": 1,\n",
    "    \"no\": 0,\n",
    "    \"false\": 0,\n",
    "    \"0\": 0\n",
    "})\n",
    "\n",
    "# Check cleaned unique values\n",
    "print(df_cleaned[\"is duplo?\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e04421bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Brick', 'Plate', 'plate', 'brick', 'tile'], dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size type column cleaning\n",
    "# Print unique values\n",
    "df_cleaned[\"size type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2a6bed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brick' 'plate']\n"
     ]
    }
   ],
   "source": [
    "# Standardize strings\n",
    "df_cleaned[\"size type\"] = df_cleaned[\"size type\"].astype(str).str.lower()\n",
    "\n",
    "# Standardize values\n",
    "df_cleaned[\"size type\"] = df_cleaned[\"size type\"].map({\n",
    "    \"tile\": \"plate\",\n",
    "    \"plate\": \"plate\",\n",
    "    \"brick\": \"brick\",\n",
    "})\n",
    "# Check cleaned unique values\n",
    "print(df_cleaned[\"size type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b2a0dbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rectangle', 'square', 'circle', 'trapezium', 'triangle',\n",
       "       'trapezoid', 'round', 'wadge'], dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base shape column cleaning\n",
    "# Print unique values\n",
    "df_cleaned[\"base shape\"].unique()\n",
    "# Standardize strings\n",
    "df_cleaned[\"base shape\"] = df_cleaned[\"base shape\"].astype(str).str.lower()\n",
    "# Print unique values again\n",
    "df_cleaned[\"base shape\"].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6e9b4e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rectangle', 'square', 'circle', 'trapezoid', 'triangle'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize strings\n",
    "df_cleaned[\"base shape\"] = df_cleaned[\"base shape\"].astype(str).str.lower()\n",
    "# Print unique values again\n",
    "df_cleaned[\"base shape\"].unique()\n",
    "\n",
    "# Standardize values\n",
    "df_cleaned[\"base shape\"] = df_cleaned[\"base shape\"].map({\n",
    "    \"rectangle\": \"rectangle\",\n",
    "    \"square\": \"square\",\n",
    "    \"circle\": \"circle\",\n",
    "    \"round\": \"circle\",\n",
    "    \"triangle\": \"triangle\",\n",
    "    \"wadge\": \"triangle\",\n",
    "    \"trapezoid\": \"trapezoid\",\n",
    "    \"trapezium\": \"trapezoid\",\n",
    "})\n",
    "\n",
    "df_cleaned[\"base shape\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c560b63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2x4', '2x2', '2x8', '1x4', '1x3', '2x6', '1x2', '4x6', '1x1',\n",
       "       '2x3', '0x0', '2x4+2x2', '2*4', '2*8', '2*2', '2*6', '2*3', '1*3',\n",
       "       '1*4', '1*2', '1*1', '4*6', '4x2', '8x2', '6x2', '4x1', '2x1',\n",
       "       '3x2', '6x4', '4x4', '3x1', '4*4'], dtype=object)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base dimensions column cleaning\n",
    "# Print unique values\n",
    "df_cleaned[\"base dimensions\"].unique()\\\n",
    "# Standardize strings\n",
    "df_cleaned[\"base dimensions\"] = df_cleaned[\"base dimensions\"].astype(str).str.lower().str.replace(\" \", \"\")\n",
    "# Print unique values again\n",
    "df_cleaned[\"base dimensions\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5af33ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2x4' '2x2' '2x8' '1x4' '1x3' '2x6' '1x2' '4x6' '1x1' '2x3' '0x0'\n",
      " '2x4+2x2' '4x2' '8x2' '6x2' '4x1' '2x1' '3x2' '6x4' '4x4' '3x1']\n"
     ]
    }
   ],
   "source": [
    "# Replace * with x for consistency\n",
    "df_cleaned[\"base dimensions\"] = df_cleaned[\"base dimensions\"].str.replace(\"*\", \"x\", regex=False)\n",
    "\n",
    "# Check the unique values\n",
    "print(df_cleaned[\"base dimensions\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f346272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2x4' '2x2' '2x8' '1x4' '1x3' '2x6' '1x2' '4x6' '1x1' '2x3' '0x0'\n",
      " '2x2+2x4' '4x4']\n"
     ]
    }
   ],
   "source": [
    "# Normalize base dimensions so that order doesn't matter *Code Generated by AI*\n",
    "df_cleaned[\"base dimensions\"] = df_cleaned[\"base dimensions\"].apply(\n",
    "    lambda dim: np.nan if pd.isna(dim) or str(dim).strip() == \"\" or str(dim).replace(\" \", \"\").lower() == \"2x2+2x4\"\n",
    "    else \"+\".join(sorted([\"x\".join(sorted(b.lower().replace(\" \", \"\").replace(\"*\", \"x\").split(\"x\"))) for b in str(dim).split(\"+\")]))\n",
    ")\n",
    "\n",
    "# Check unique values\n",
    "print(df_cleaned[\"base dimensions\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "81eaa79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Number of studs column cleaning\n",
    "# Get type\n",
    "print(df_cleaned[\"number of studs\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d39c56f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, 45.,  0., 15., 30.])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slope degree column cleaning\n",
    "# Get type\n",
    "print(df_cleaned[\"slope degree\"].dtype)\n",
    "df_cleaned[\"slope degree\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "54daae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with 0.0\n",
    "df_cleaned[\"slope degree\"] = df_cleaned[\"slope degree\"].fillna(0.0)\n",
    "\n",
    "# Check that there are no missing values left\n",
    "print(df_cleaned[\"slope degree\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e80846fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x_/zccbsk657rb51hx1tc0t1ss80000gn/T/ipykernel_95762/3348433945.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_cleaned[\"in stock\"] = df_cleaned[\"in stock\"].replace({\n"
     ]
    }
   ],
   "source": [
    "# In stock column cleaning\n",
    "# Get unique values\n",
    "df_cleaned[\"in stock\"].unique()\n",
    "df_cleaned[\"in stock\"] = df_cleaned[\"in stock\"].replace({\n",
    "    \"yes\": 1,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "332ac867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# Transparent column cleaning\n",
    "# Get type\n",
    "print(df_cleaned[\"transparent\"].dtype)\n",
    "\n",
    "# Fill missing values and convert to integer\n",
    "df_cleaned[\"transparent\"] = pd.to_numeric(df_cleaned[\"transparent\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
