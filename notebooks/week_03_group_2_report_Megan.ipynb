{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b583a02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13bbd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02591d4a-8e1a-4e02-a08d-0a0e6ca38fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_excel(\"../additional_materials/Lego Database.xlsx\", sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b9bf232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['group1', 'group 2', 'group_3', 'group 4', 'group_5', 'Sheet5']\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "excel_file = pd.ExcelFile(\"../additional_materials/Lego Database.xlsx\")\n",
    "\n",
    "# See what sheets it contains\n",
    "print(excel_file.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4ac4750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id      color is duplo? size type base shape base dimensions  \\\n",
      "0  NaN  Dark Blue      True     Brick  Rectangle           2 x 4   \n",
      "1  NaN      Green      True     Brick  Rectangle           2 x 4   \n",
      "2  NaN      Coral      True     Brick     Square           2 x 2   \n",
      "3  NaN        Red      True     Brick     Square           2 x 2   \n",
      "4  NaN      White      True     Brick     Square           2 x 2   \n",
      "\n",
      "   number of studs has slope?  slope degree in stock  transparent  \n",
      "0              8.0      False           NaN        1          NaN  \n",
      "1              8.0      False           NaN        1          NaN  \n",
      "2              4.0      False           NaN        1          NaN  \n",
      "3              4.0      False           NaN        1          NaN  \n",
      "4              4.0      False           NaN        1          NaN  \n",
      "Total rows: 204\n"
     ]
    }
   ],
   "source": [
    "# Read all sheets into a dictionary of DataFrames\n",
    "all_sheets = pd.read_excel(excel_file, sheet_name=None)\n",
    "\n",
    "# Combine them all\n",
    "df_combined = pd.concat(all_sheets.values(), ignore_index=True)\n",
    "\n",
    "print(df_combined.head())\n",
    "print(f\"Total rows: {len(df_combined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame to store clean data\n",
    "df_cleaned = df_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ea11fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204, 13)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get shape\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40c3c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the id column with index\n",
    "df_cleaned['id'] = range(1, len(df_cleaned) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22be3131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dark Blue', 'Green', 'Coral', 'Red', 'White', 'Light Green',\n",
       "       'Orange', 'Yellow', 'Brown', 'Purple', 'Lilac', 'Orchid',\n",
       "       'Dark Grey', 'Light Grey', 'Pink', 'Dark Green', 'Cream', 'Black',\n",
       "       'Red Brown', 'Neon Yellow', 'Cyan', 'Denim Blue', 'Ice Blue',\n",
       "       'Capri', 'Shiny Green', 'Olive Green', 'Beige', 'Bright Pink',\n",
       "       'Transparent', 'lightgreen', 'lightbrown', 'lightpink', 'red',\n",
       "       'yellow', 'darkblue', 'darkgreen', 'darkpink', 'orange',\n",
       "       'darkpurple', 'lightpurple', 'white', 'grey', 'mudbrown', 'black',\n",
       "       'turquoise', 'lightblue', 'neon orange', 'neon dark yellow',\n",
       "       'neon light yellow', 'darkbrown', 'bright green', 'pink', 'peach',\n",
       "       'blue', 'pear', 'dark green ', 'dark green', 'sky blue',\n",
       "       'bright yellow', 'navy blue', 'purple', 'maroon', 'cream', 'khaki',\n",
       "       'neon green', 'neon yellow', 'neon blue', 'coral', 'lime green',\n",
       "       'green', 'brick red', 'cyan', 'baby blue', 'cafe', 'hot magent',\n",
       "       'Green ', 'Blue', 'Grey', 'Sky Blue', 'Deep Blue', 'Sky blue',\n",
       "       'Transparent yellow', 'Transparent orange', 'Blck',\n",
       "       'Transparent sky blue'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Color column cleaning\n",
    "df_cleaned[\"color\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0065d36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['darkblue', 'green', 'coral', 'red', 'white', 'lightgreen',\n",
       "       'orange', 'yellow', 'brown', 'purple', 'lilac', 'orchid',\n",
       "       'darkgrey', 'lightgrey', 'pink', 'darkgreen', 'cream', 'black',\n",
       "       'redbrown', 'neonyellow', 'cyan', 'denimblue', 'iceblue', 'capri',\n",
       "       'shinygreen', 'olivegreen', 'beige', 'brightpink', 'transparent',\n",
       "       'lightbrown', 'lightpink', 'darkpink', 'darkpurple', 'lightpurple',\n",
       "       'grey', 'mudbrown', 'turquoise', 'lightblue', 'neonorange',\n",
       "       'neondarkyellow', 'neonlightyellow', 'darkbrown', 'brightgreen',\n",
       "       'peach', 'blue', 'pear', 'skyblue', 'brightyellow', 'navyblue',\n",
       "       'maroon', 'khaki', 'neongreen', 'neonblue', 'limegreen',\n",
       "       'brickred', 'babyblue', 'cafe', 'hotmagent', 'deepblue',\n",
       "       'transparentyellow', 'transparentorange', 'blck',\n",
       "       'transparentskyblue'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove spaces and convert to lowercase\n",
    "df_cleaned[\"color\"] = df_cleaned[\"color\"].str.lower().str.replace(\" \", \"\")\n",
    "df_cleaned[\"color\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef557a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that contains the base color\n",
    "# Original mapping\n",
    "color_map = {\n",
    "    'blue': ['darkblue', 'denimblue', 'iceblue', 'capri', 'lightblue', 'blue', 'skyblue', 'navyblue', 'deepblue', 'babyblue', 'neonblue', 'transparentskyblue', 'cyan', 'turquoise'],\n",
    "    'green': ['green', 'lightgreen', 'darkgreen', 'shinygreen', 'olivegreen', 'brightgreen', 'limegreen', 'neongreen', 'pear'],\n",
    "    'red': ['red', 'coral', 'redbrown', 'brickred', 'maroon' ],\n",
    "    'yellow': ['yellow', 'neonyellow', 'neonlightyellow', 'brightyellow', 'transparentyellow', 'neondarkyellow'],\n",
    "    'orange': ['orange', 'peach', 'neonorange', 'transparentorange'],\n",
    "    'brown': ['brown', 'lightbrown', 'darkbrown', 'mudbrown', 'cafe', 'khaki', 'beige', 'cream'],\n",
    "    'pink': ['pink', 'lightpink', 'darkpink', 'brightpink', 'orchid', 'lilac', 'hotmagent'],\n",
    "    'purple': ['purple', 'darkpurple', 'lightpurple'],\n",
    "    'grey': ['darkgrey', 'lightgrey', 'grey'],\n",
    "    'white': ['white'],\n",
    "    'black': ['black', 'blck'],\n",
    "    'transparent': ['transparent']\n",
    "}\n",
    "\n",
    "# Reverse mapping: detailed color â†’ general color\n",
    "flat_color_map = {detailed: general for general, lst in color_map.items() for detailed in lst}\n",
    "\n",
    "# Now map works\n",
    "df_cleaned[\"color base shade\"] = df_cleaned[\"color\"].map(flat_color_map)\n",
    "df_cleaned[\"color base shade\"].unique()\n",
    "\n",
    "# Reset the index and drop the old one\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "\n",
    "# Get the list of columns\n",
    "cols = df_cleaned.columns.tolist()\n",
    "\n",
    "# Remove 'color_base_shade' from its current position\n",
    "cols.remove('color base shade')\n",
    "\n",
    "# Find the index of 'color' column\n",
    "color_index = cols.index('color')\n",
    "\n",
    "# Insert 'color_base_shade' right after 'color'\n",
    "cols.insert(color_index + 1, 'color base shade')\n",
    "\n",
    "# Reorder the dataframe\n",
    "df_cleaned = df_cleaned[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c110d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([True, False, 'yes', 'no'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is Duplo? column cleaning\n",
    "# Print unique values\n",
    "df_cleaned[\"is duplo?\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fa655d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "# Standardize strings\n",
    "df_cleaned[\"is duplo?\"] = df_cleaned[\"is duplo?\"].astype(str).str.lower()\n",
    "\n",
    "# Standardize values\n",
    "df_cleaned[\"is duplo?\"] = df_cleaned[\"is duplo?\"].map({\n",
    "    \"yes\": 1,\n",
    "    \"true\": 1,\n",
    "    \"1\": 1,\n",
    "    \"no\": 0,\n",
    "    \"false\": 0,\n",
    "    \"0\": 0\n",
    "})\n",
    "\n",
    "# Check cleaned unique values\n",
    "print(df_cleaned[\"is duplo?\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e04421bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Brick', 'Plate', 'plate', 'brick', 'tile'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size type column cleaning\n",
    "# Print unique values\n",
    "df_cleaned[\"size type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a6bed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brick' 'plate']\n"
     ]
    }
   ],
   "source": [
    "# Standardize strings\n",
    "df_cleaned[\"size type\"] = df_cleaned[\"size type\"].astype(str).str.lower()\n",
    "\n",
    "# Standardize values\n",
    "df_cleaned[\"size type\"] = df_cleaned[\"size type\"].map({\n",
    "    \"tile\": \"plate\",\n",
    "    \"plate\": \"plate\",\n",
    "    \"brick\": \"brick\",\n",
    "})\n",
    "# Check cleaned unique values\n",
    "print(df_cleaned[\"size type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2a0dbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rectangle', 'square', 'circle', 'trapezium', 'triangle',\n",
       "       'trapezoid', 'round', 'wadge'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base shape column cleaning\n",
    "# Print unique values\n",
    "df_cleaned[\"base shape\"].unique()\n",
    "# Standardize strings\n",
    "df_cleaned[\"base shape\"] = df_cleaned[\"base shape\"].astype(str).str.lower()\n",
    "# Print unique values again\n",
    "df_cleaned[\"base shape\"].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e9b4e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rectangle', 'square', 'circle', 'trapezoid', 'triangle'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize strings\n",
    "df_cleaned[\"base shape\"] = df_cleaned[\"base shape\"].astype(str).str.lower()\n",
    "# Print unique values again\n",
    "df_cleaned[\"base shape\"].unique()\n",
    "\n",
    "# Standardize values\n",
    "df_cleaned[\"base shape\"] = df_cleaned[\"base shape\"].map({\n",
    "    \"rectangle\": \"rectangle\",\n",
    "    \"square\": \"square\",\n",
    "    \"circle\": \"circle\",\n",
    "    \"round\": \"circle\",\n",
    "    \"triangle\": \"triangle\",\n",
    "    \"wadge\": \"triangle\",\n",
    "    \"trapezoid\": \"trapezoid\",\n",
    "    \"trapezium\": \"trapezoid\",\n",
    "})\n",
    "\n",
    "df_cleaned[\"base shape\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c560b63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2x4', '2x2', '2x8', '1x4', '1x3', '2x6', '1x2', '4x6', '1x1',\n",
       "       '2x3', '0x0', '2x4+2x2', '2*4', '2*8', '2*2', '2*6', '2*3', '1*3',\n",
       "       '1*4', '1*2', '1*1', '4*6', '4x2', '8x2', '6x2', '4x1', '2x1',\n",
       "       '3x2', '6x4', '4x4', '3x1', '4*4'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base dimensions column cleaning\n",
    "# Print unique values\n",
    "df_cleaned[\"base dimensions\"].unique()\\\n",
    "# Standardize strings\n",
    "df_cleaned[\"base dimensions\"] = df_cleaned[\"base dimensions\"].astype(str).str.lower().str.replace(\" \", \"\")\n",
    "# Print unique values again\n",
    "df_cleaned[\"base dimensions\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5af33ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2x4' '2x2' '2x8' '1x4' '1x3' '2x6' '1x2' '4x6' '1x1' '2x3' '0x0'\n",
      " '2x4+2x2' '4x2' '8x2' '6x2' '4x1' '2x1' '3x2' '6x4' '4x4' '3x1']\n"
     ]
    }
   ],
   "source": [
    "# Replace * with x for consistency\n",
    "df_cleaned[\"base dimensions\"] = df_cleaned[\"base dimensions\"].str.replace(\"*\", \"x\", regex=False)\n",
    "\n",
    "# Check the unique values\n",
    "print(df_cleaned[\"base dimensions\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f346272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2x4' '2x2' '2x8' '1x4' '1x3' '2x6' '1x2' '4x6' '1x1' '2x3' '0x0'\n",
      " '2x2+2x4' '4x4']\n"
     ]
    }
   ],
   "source": [
    "# Normalize base dimensions so that order doesn't matter *Code Generated by AI*\n",
    "df_cleaned[\"base dimensions\"] = df_cleaned[\"base dimensions\"].apply(\n",
    "    lambda dim: np.nan if pd.isna(dim) or str(dim).strip() == \"\" or str(dim).replace(\" \", \"\").lower() == \"2x2+2x4\"\n",
    "    else \"+\".join(sorted([\"x\".join(sorted(b.lower().replace(\" \", \"\").replace(\"*\", \"x\").split(\"x\"))) for b in str(dim).split(\"+\")]))\n",
    ")\n",
    "\n",
    "# Check unique values\n",
    "print(df_cleaned[\"base dimensions\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81eaa79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# Number of studs column cleaning\n",
    "# Get type\n",
    "print(df_cleaned[\"number of studs\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "febd460d-60e9-4949-a605-4cb8e6880ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"has slope?\"] = df_cleaned[\"has slope?\"].replace({\n",
    "    \"yes\": 1,\n",
    "    \"true\": 1,\n",
    "    \"1\": 1,\n",
    "    \"no\": 0,\n",
    "    \"false\": 0,\n",
    "    \"0\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e15f286b-fecf-4e2f-80b8-532ed0ea2132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has slope?\n",
       "False    180\n",
       "True      24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned[\"has slope?\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d39c56f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, 45.,  0., 15., 30.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slope degree column cleaning\n",
    "# Get type\n",
    "print(df_cleaned[\"slope degree\"].dtype)\n",
    "df_cleaned[\"slope degree\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54daae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with 0.0\n",
    "df_cleaned[\"slope degree\"] = df_cleaned[\"slope degree\"].fillna(0.0)\n",
    "\n",
    "# Check that there are no missing values left\n",
    "print(df_cleaned[\"slope degree\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e80846fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/64/4f9k2wyx0r14830_8g7xntcw0000gn/T/ipykernel_38369/3348433945.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_cleaned[\"in stock\"] = df_cleaned[\"in stock\"].replace({\n"
     ]
    }
   ],
   "source": [
    "# In stock column cleaning\n",
    "# Get unique values\n",
    "df_cleaned[\"in stock\"].unique()\n",
    "df_cleaned[\"in stock\"] = df_cleaned[\"in stock\"].replace({\n",
    "    \"yes\": 1,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "332ac867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# Transparent column cleaning\n",
    "# Get type\n",
    "print(df_cleaned[\"transparent\"].dtype)\n",
    "\n",
    "# Fill missing values and convert to integer\n",
    "df_cleaned[\"transparent\"] = pd.to_numeric(df_cleaned[\"transparent\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
